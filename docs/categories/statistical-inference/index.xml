<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>    <link>https://s3alfisc.github.io/blog/categories/statistical-inference/</link>
    <description>Recent blog posts by </description>    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 29 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://s3alfisc.github.io/blog/categories/statistical-inference/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A üê¥ race: The Wild Cluster Bootstrap vs Satterthwaite-corrected Sandwich Estimators when the number of Clusters is small</title>
      <link>https://s3alfisc.github.io/blog/post/2022-01-29-cluster-robust-inference-when-the-number-of-clusters-is-small-a-horse-race/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://s3alfisc.github.io/blog/post/2022-01-29-cluster-robust-inference-when-the-number-of-clusters-is-small-a-horse-race/</guid>
   <description>
&lt;script src=&#34;https://s3alfisc.github.io/blog/post/2022-01-29-cluster-robust-inference-when-the-number-of-clusters-is-small-a-horse-race/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;A couple of months ago, Gordon Burtch shared an excellent Twitter thread on the merits of wild cluster bootstrap inference when the regression error terms are clustered into a small group of clusters:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How biased are clustered SEs with &amp;#39;few&amp;#39; clusters? A simulation illustrating this. DGP is y~x, 50 clusters, x is normal, true beta is 0.5. Plot of 1000 sims, beta estimate +95% CIs for each. Red = we did not cover true beta. Std SEs no good, clustered SEs yield ~95% coverage (1/6) &lt;a href=&#34;https://t.co/z3eZdy1wb1&#34;&gt;pic.twitter.com/z3eZdy1wb1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Gord Burtch (@gburtch) &lt;a href=&#34;https://twitter.com/gburtch/status/1378520203689082886?ref_src=twsrc%5Etfw&#34;&gt;April 4, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;!-- &lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;How biased are clustered SEs with &amp;#39;few&amp;#39; clusters? A simulation illustrating this. DGP is y~x, 50 clusters, x is normal, true beta is 0.5. Plot of 1000 sims, beta estimate +95% CIs for each. Red = we did not cover true beta. Std SEs no good, clustered SEs yield ~95% coverage (1/6) &lt;a href=&#34;https://t.co/z3eZdy1wb1&#34;&gt;pic.twitter.com/z3eZdy1wb1&lt;/a&gt;&lt;/p&gt;&amp;mdash; Gord Burtch (@gburtch) &lt;a href=&#34;https://twitter.com/gburtch/status/1378520203689082886?ref_src=twsrc%5Etfw&#34;&gt;April 4, 2021&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;  --&gt;
&lt;p&gt;In his simulation study, Gordon compared the performance of the wild cluster bootstrap with regular sandwich cluster robust variance estimators (CRVE). As I am quite invested in the wild cluster bootstrap, I was happy to see that it appeared to outperform ‚Äòclassical‚Äô robust standard errors: in his simulations, the coverage rate of wild clustered bootstrapped confidence intervals is already close to the desired coverage rate of 95% even for a small number of clusters (e.g.¬†5-10).&lt;/p&gt;
&lt;!-- Have you ever heard of Satterthwaite degree-of-freedom bias-corrections for cluster robust standard error estimation? --&gt;
&lt;!-- Well, I myself have never seen them used in any applied econometrics paper \footnote{As it happens, Angrist \&amp; Lavy ... }. But while writing this blog post, I realized that both the survey paper by [Cameron &amp; Miller](http://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf) and Mostly Harmless Econometrics both discuss ... --&gt;
&lt;p&gt;Nevertheless, there is a statistical literature that argues that it is fine to use cluster robust sandwich estimators to compute standard errors for a small number of clusters as long as one applies an appropriate &lt;strong&gt;small sample correction&lt;/strong&gt; via &lt;strong&gt;Satterthwaite&lt;/strong&gt; or &lt;strong&gt;saddlepoint corrections&lt;/strong&gt; (Imbens &amp;amp; Kolesar, Bell, Tipton &amp;amp; Pustejovksy).
All these methods are implemented in R via the &lt;code&gt;clubSandwich&lt;/code&gt; package and in Stata in the &lt;a href=&#34;https://github.com/jepusto/clubSandwich-Stata&#34;&gt;clubSandwich-Stata&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Of course I was curious to see how the Satterthwaite-corrected SEs would perform in comparison to the would cluster bootstrap, so I decided to run some simulations.&lt;/p&gt;
&lt;p&gt;Luckily for me, Gordon published all of his code &lt;a href=&#34;https://github.com/gburtch/simulating_cluster_SEs&#34;&gt;on github&lt;/a&gt;, so it was easy for me to slightly tweak it and add simulations for Satterthwaite corrections. Open software is really awesome!&lt;/p&gt;
&lt;p&gt;I have collected my minor updates of Gordon‚Äôs code in an R package, which is available on &lt;a href=&#34;https://github.com/s3alfisc/clusteredErrorsSims&#34;&gt;github&lt;/a&gt;. To reproduce all analyses below, you simply have to install the package by running&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;devtools&amp;quot;)
devtools::install_github(&amp;quot;s3alfisc/clusteredErrorsSims&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But before we dive into the simulations, I will start with revising some theory on the consistency of CRVE that will motivate the design of the simulations.&lt;/p&gt;
&lt;div id=&#34;when-are-clustered-standard-errors-biased&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;When are clustered standard errors biased?&lt;/h2&gt;
&lt;p&gt;In general, cluster robust variance estimators might be biased if one of the three conditions below holds:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;If there are only very few clusters.&lt;/li&gt;
&lt;li&gt;If the cluster sizes are wildly different.&lt;/li&gt;
&lt;li&gt;If the intra-cluster correlations varies across clusters.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the following simulations, I will focus on cases 1-2 and conduct three simulation studies. The &lt;strong&gt;first&lt;/strong&gt; simulation closely follows Gordon‚Äôs work and investigates the performances of different inference methods for a &lt;strong&gt;small number of clusters G&lt;/strong&gt;, but includes simulations for Satterthwaite corrected CRVE estimates via the &lt;code&gt;clubSandwich&lt;/code&gt; package. The &lt;strong&gt;second&lt;/strong&gt; set of simulations investigates the performance for clustered errors with &lt;span class=&#34;math inline&#34;&gt;\(G \in \{50, 100\}\)&lt;/span&gt; clusters, but &lt;strong&gt;wildly different&lt;/strong&gt; cluster sizes. Last, I take a look at a special case that has received considerable attention: how do wild cluster bootstrap and Satterthwaite corrected SEs perform when only few clusters are treated (as often happens with Difference-in-Differences identification strategies)? Simulations 2 and 3 are heavily influenced by work by &lt;a href=&#34;https://ageconsearch.umn.edu/record/274639/files/qed_wp_1314.pdf&#34;&gt;MacKinnon &amp;amp; Webb&lt;/a&gt; on the performance of the wild cluster bootstrap under ‚Äúwildly different‚Äù cluster sizes.&lt;/p&gt;
&lt;p&gt;The data generating process for all simulations is a simple linear regression model for &lt;span class=&#34;math inline&#34;&gt;\(g = 1, ..., G\)&lt;/span&gt; clusters:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  y_{ig} = \beta_0 + \beta_1 X_{ig} + \epsilon_{ig}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{ig}|X_{ig}) = 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0 = 1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1 = 0.5\)&lt;/span&gt; and the errors &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ig}\)&lt;/span&gt; are simulated to be correlated within &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; clusters with intra-cluster correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. All errors are uncorrelated across clusters.&lt;/p&gt;
&lt;p&gt;So the stage is set for a üê¥ race! My champion, of course, is the wild cluster bootstrap, but let‚Äôs see how the bias-corrected standard errors perform in comparison!&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:pressure&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;Le_jockey.jpg&#34; alt=&#34;Toulose-Lautrec, Le Jockey, 1899&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Toulose-Lautrec, Le Jockey, 1899
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-1-small-number-of-clusters-g-balanced-cluster-sizes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simulation 1: Small number of clusters G &amp;amp; balanced cluster sizes&lt;/h4&gt;
&lt;p&gt;To initiate the horse race, you simply have to run the &lt;code&gt;sim_balanced_clusters()&lt;/code&gt; function, though I want to note that on my laptop, this takes around 2h while using multiple cores. By default, the wild cluster bootstrap will run with &lt;span class=&#34;math inline&#34;&gt;\(B = 9999\)&lt;/span&gt; bootstrap iterations throughout all simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clusteredErrorsSims)
set.seed(1234)
sim_balanced_clusters(n = 1000, n_sims = 1000, rho = 0.7, workers = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the results for the first simulation:&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:Result1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;CI%20Coverage%20for%20Several%20Cluster%20Robust%20Inference%20Methods.png&#34; alt=&#34;Simulation results. N = 1000, rho = 0.7, balanced cluster sizes&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Simulation results. N = 1000, rho = 0.7, balanced cluster sizes
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;There are three takeaways from figure 2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;As expected, inference with non-robust standard errors is severely biased.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For less than 50 clusters, the coverage rate for the CRVE based confidence intervals is always lower than 95%: inference based on uncorrected CRVEs underestimate the variability of the parameter of interest, &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The wild cluster bootstrap &lt;strong&gt;and&lt;/strong&gt; cluster robust variance estimator with Satterthwaite correction perform astonishingly well for 3 or more clusters. For a number of cluster with of &lt;span class=&#34;math inline&#34;&gt;\(3 \leq G \leq 10\)&lt;/span&gt;, the Satterthwaite correction seems to perform slightly better than the wild cluster bootstrap.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-2-wildly-different-cluster-sizes&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Simulation 2: Wildly different cluster sizes&lt;/h4&gt;
&lt;p&gt;Instead of simulating balanced cluster sizes, I now follow &lt;a href=&#34;https://ageconsearch.umn.edu/record/274639/files/qed_wp_1314.pdf&#34;&gt;MacKinnon &amp;amp; Webb&lt;/a&gt; and simulate group sizes that mimic the relative size of the US states (minus Washington DC) for &lt;span class=&#34;math inline&#34;&gt;\(G=50\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(G = 100\)&lt;/span&gt; clusters. The dgp is unchanged, but in parallel to MacKinnon &amp;amp; Webb‚Äôs work, I set the number of observations &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(2.000\)&lt;/span&gt;. I also increase the number of Monte Carlo simulations to &lt;code&gt;n_sim = 10.000&lt;/code&gt; and repeat the analysis for a range of intra-cluster correlations &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:Figure3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;wildly_different.png&#34; alt=&#34;Simulation results. N = 2000, 50 and 100 clusters, wildly different cluster sizes&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Simulation results. N = 2000, 50 and 100 clusters, wildly different cluster sizes
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Both for &lt;span class=&#34;math inline&#34;&gt;\(G = 50\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(G = 100\)&lt;/span&gt;, the wild cluster bootstrap and Satterthwaite corrected errors perform equally well and achieve close to 95% coverage for all intra-cluster correlations &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The unadjusted CRVEs instead only achieve coverage rates of around 93 and 94%.&lt;/p&gt;
&lt;p&gt;You can reproduce Figure 2 by running&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;wildly_different_sim(n = 2000, n_sims = 5000, workers = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once again, note that this function will run for a very long time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;treatment-effects&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Treatment Effects&lt;/h4&gt;
&lt;p&gt;The last simulation investigates a topic that has received considerable attention: regression models where the treatment occurs at the cluster level, but only few clusters are treated (e.g.¬†&lt;a href=&#34;https://academic.oup.com/qje/article-abstract/119/1/249/1876068?redirectedFrom=fulltext&amp;amp;login=false&#34;&gt;‚ÄúHow much should we trust DiD estimates?&lt;/a&gt;‚Äú)? For the sake of simplicity, I do not simulate a‚Äùfull‚Äù DiD model with 2-way fixed effects and potential error correlations across time but restrict myself to replacing &lt;span class=&#34;math inline&#34;&gt;\(X_{ig}\)&lt;/span&gt; in the model above by a treatment assignment dummy &lt;span class=&#34;math inline&#34;&gt;\(D_{ig}\)&lt;/span&gt; - the simulation hence mirrors a cluster randomized experiment. (Loosely) following MacKinnon &amp;amp; Webb once again, I then simulate &lt;span class=&#34;math inline&#34;&gt;\(N=2000\)&lt;/span&gt; observations with intra-cluster correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0.5\)&lt;/span&gt; and vary the number of clusters that are treated. The simulations are repeated for different proportions of treated clusters &lt;span class=&#34;math inline&#34;&gt;\(P \in \{1/50, ..., 1\}\)&lt;/span&gt;, where the clusters are a) of equal size, b) US-state sized and sorted in increasing order and c) US-state sized and sorted in decreasing order.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;treatment_effect_sim(n = 2000, n_sims = 10000, workers = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:Figure4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;treatment_simulations.png&#34; alt=&#34;Treatment Effect Simulations, N = 2000, 50 clusters, treatment effects. The x axis denotes the share of treated clusters, either in increasing or decreasing cluster size.&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Treatment Effect Simulations, N = 2000, 50 clusters, treatment effects. The x axis denotes the share of treated clusters, either in increasing or decreasing cluster size.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once again, both the wild cluster bootstrap and Satterthwaite correction perform well for a wide range of treated clusters. For more extreme shares of treated clusters, the wild cluster bootstrap‚Äôs coverage rate approaches 1, while the Satterthwaite corrected CRVE‚Äôs coverage rate is as low as the regular CRVE‚Äôs, whose coverage rate starts to deviate from the desired coverage level of 95% already at less extreme shares of treated clusters than both bootstrap and Satterthwaite correction.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;So, when should you use Satterthwaite corrected cluster robust standard errors, and when should you rely on the wild cluster bootstrap in case you are facing a small number of clusters problem or data with wildly different cluster sizes? The honest answer is that I still don‚Äôt know &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. All in all, my main learning from the simulations above is that the Satterthwaite correction method might perform just as well as the wild cluster bootstrap. I am quite impressed by the performance of the Satterthwaite corrected cluster robust sandwich estimator!&lt;/p&gt;
&lt;!-- ### When the parameter of interest is a treatment effect  --&gt;
&lt;!-- In a final simulation, I investigate the (probably) most popular regression specification in all of economics: the regression specification of a Difference-in-Differences strategy - a two-way fixed effects model with a binary variable $D$, a treatment effect.   --&gt;
&lt;!-- Difference-in-Differences models are usually estimated by an  equation similar to  --&gt;
&lt;!-- $$ --&gt;
&lt;!--   y_{igt} =  --&gt;
&lt;!-- $$ --&gt;
&lt;!-- The parameter of interest ... But what happens if only few clusters are treated? Dangers of the pairs bootstrap - bootstrap samples without any treatment group. Solution wild cluster bootstrap. The paper by MacKinnon &amp; Webb argues that the wild cluster bootstrap performs really well if few clusters are treated. Here, I will replicate MW&#39;s analysis for the WCB and compare it with the performance of Satterthwaite corrected robust estimators.  --&gt;
&lt;!-- Again, the data simulating process mimics the equation above. I further set $G = 50$ and the intra-cluster correlation $\rho = $ as in MW. Once again, the sample size is $N = 2000$, and the ...  --&gt;
&lt;/div&gt;
&lt;div id=&#34;code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;You can find all code to reproduce the analyses above in this &lt;a href=&#34;https://github.com/s3alfisc/clusteredErrorsSims&#34;&gt;github repo&lt;/a&gt;. It‚Äôs essentially a clone of code written by Gord Burtch - my estimate for a lower bound of the share of Gordon‚Äôs code is 80%. You can find his code &lt;a href=&#34;https://github.com/gburtch/simulating_cluster_SEs&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;literature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Literature&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;&#34;&gt;Bell &amp;amp; McCaffrey - ‚ÄúBias reduction in standard errors for linear regression with multi-stage samples‚Äù, Survey Methodology (2002)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nber.org/system/files/working_papers/t0344/t0344.pdf&#34;&gt;Cameron, Gelbach &amp;amp; Miller - ‚ÄúBootstrap-based improvements for inference with clustered errors‚Äù, Review of Economics &amp;amp; Statistics (2008)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nber.org/system/files/working_papers/w18478/w18478.pdf&#34;&gt;Imbens &amp;amp; Kolesar - ‚ÄúRobust standard errors in small samples: Some practical advice‚Äù, Review of Economics and Statistics (2016)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ageconsearch.umn.edu/record/274639/files/qed_wp_1314.pdf&#34;&gt;MacKinnon &amp;amp; Webb - ‚ÄúWild bootstrap inference for wildly different cluster sizes‚Äù, Journal of Applied Econometrics (2017)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1601.01981.pdf&#34;&gt;Pustejovsky &amp;amp; Tipton - ‚ÄúSmall-sample methods for cluster-robust variance estimation and hypothesis testing in fixed effects models‚Äù, Journal of Economics and Business Statistics (2018)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.econstor.eu/bitstream/10419/97480/1/757403891.pdf&#34;&gt;Webb - ‚ÄúReworking wild bootstrap based inference for clustered errors‚Äù, Working Paper (2013)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Note that MacKinnon and Webb conduct Monte Carlo studies on the WCB with several 100K iterations, so it might be necessary to increase the number of iterations to make more definite statements.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>    </item>
    
    <item>
      <title>1000x faster Wild Cluster Bootstrap Inference in R with fwildclusterboot üöÄ</title>
      <link>https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/</guid>
   <description>
&lt;script src=&#34;https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When you suspect that the error terms in your regression model are correlated within clusters, and the number of clusters is small, trouble might be running at you. In such a situation, common cluster robust standard errors tend to be downward biased - they are too eager to reject the null hypothesis. Since &lt;a href=&#34;https://www.jstor.org/stable/40043157&#34;&gt;Cameron, Gelbach &amp;amp; Miller&lt;/a&gt; first suggested that the wild cluster bootstrap might be preferable to sandwich standard errors when the number of clusters is small, it has become common practice among empirical economists to check their cluster robust inferences against the wild cluster bootstrap.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:pressure&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;duerer_lion.jpg&#34; alt=&#34;Not a wild bootstrap, but a wild lion, by Albrecht Duerer&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Not a wild bootstrap, but a wild lion, by Albrecht Duerer
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;At some point, I found myself in a ‚Äúsmall number of clusters‚Äù situation. I was trying to estimate a treatment effect for a sample of a few thousand observations, which were grouped into around 20 clusters. So I started to search for R packages that implement the wild cluster bootstrap, and found two implementations on CRAN: &lt;code&gt;sandwich&lt;/code&gt; and &lt;code&gt;clusterSEs&lt;/code&gt;. I opted for the &lt;code&gt;sandwich&lt;/code&gt; package (because it‚Äôs actually a really great package) and fit my regression model via &lt;code&gt;lm()&lt;/code&gt;. Then I started to bootstrap with sandwich‚Äôs &lt;code&gt;vcovBS()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;So the bootstrap ran ‚Ä¶ and I waited. Eventually, I left my office to get some coffee with a colleague, returned to my desk ‚Ä¶ and the bootstrap still ran, and I waited even longer.&lt;/p&gt;
&lt;p&gt;But while the bootstrap was running, I scrolled the web and stumbled over the &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/1536867X19830877?journalCode=stja&#34;&gt;‚ÄúFast &amp;amp; Wild‚Äù paper&lt;/a&gt; by Roodman et al (2019). The claimed performance in the paper seemed to good to be true: bootstrap inference with several thousands of iterations, in a fraction of a second? The paper presents a Stata implementation of the fast algorithm, &lt;a href=&#34;https://github.com/droodman/bottest&#34;&gt;boottest&lt;/a&gt;, and that was a good enough reason for me to start up a Stata session to try it out.&lt;/p&gt;
&lt;p&gt;And indeed, &lt;code&gt;boottest&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; mind-blowingly fast: the bootstrap finished almost instantaneously. I was hooked: how was it possible that &lt;code&gt;boottest&lt;/code&gt; was &lt;em&gt;so damn fast&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Luckily, the ‚ÄúFast &amp;amp; Wild‚Äù paper explains the algorithm powering &lt;code&gt;boottest&lt;/code&gt; in great detail. Out of curiosity, I started to implement it in R, and the &lt;code&gt;fwildclusterboot&lt;/code&gt; package is the result of this effort. Now, was it worth all the work? How much faster is the ‚Äúfast algorithm‚Äù implemented in &lt;code&gt;fwildclusterboot&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;To compare &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; performance to &lt;code&gt;sandwich&lt;/code&gt;, I simulate a data set with &lt;span class=&#34;math inline&#34;&gt;\(N = 10.000\)&lt;/span&gt; observations and &lt;span class=&#34;math inline&#34;&gt;\(N_G = 42\)&lt;/span&gt; distinct clusters (42 is the magic number of clusters for which the economics profession has decided that large N asymptotics fail, see Angrist &amp;amp; Pischke‚Äôs ‚ÄúMostly Harmless‚Äù, Chapter 8.2.3) and fit a regression model via &lt;code&gt;lm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fwildclusterboot)
library(sandwich)
library(lmtest)
library(bench)

# simulate data
seed &amp;lt;- 236723478
N &amp;lt;- 10000
data &amp;lt;- fwildclusterboot:::create_data(N = N,
                                         N_G1 = 42, icc1 = 0.1,
                                         N_G2 = 20, icc2 = 0.8,
                                         numb_fe1 = 10,
                                         numb_fe2 = 10,
                                         seed = seed,
                                         weights = 1:N)
lm_fit &amp;lt;- lm(proposition_vote ~ treatment + as.factor(Q1_immigration) + as.factor(Q2_defense), data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the first experiment, the bootstrap will run for &lt;span class=&#34;math inline&#34;&gt;\(B = 9999\)&lt;/span&gt; iterations. For the estimation via &lt;code&gt;vcovBS&lt;/code&gt;, we will use 4 cores.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 9999
# wild cluster bootstrap via sandwich::vcovBS

bench1 &amp;lt;- 
bench::mark(
  boot_slow = sandwich::vcovBS(lm_fit,
                                R = B,
                                cluster = ~ group_id1,
                                cores = 4), 
  iterations = 1
)
bench1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_slow     36.9s    36.9s    0.0271    12.7MB        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;vcovBS()&lt;/code&gt; finishes in around 37 seconds - that‚Äôs not too bad, isn‚Äôt it?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wild cluster bootstrap via fwildclusterboot::boottest()
bench1f &amp;lt;- 
bench::mark(boot_fast =
                   fwildclusterboot::boottest(lm_fit,
                                              clustid = c(&amp;quot;group_id1&amp;quot;),
                                              B = B,
                                              param = &amp;quot;treatment&amp;quot;,
                                              seed = 3,
                                              nthreads = 1), 
            iterations = 25)
bench1f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast    73.3ms   81.7ms      9.48    98.7MB     26.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While &lt;code&gt;sandwich::vcovBS()&lt;/code&gt; takes almost 36.9 seconds, &lt;code&gt;fwildclusterboot::boottest()&lt;/code&gt; runs in around one fifth of a second üöÄ. Yes, really: one fifth of a second! That‚Äôs a speed gain of a factor of 451! If you don‚Äôt have 4 cores available, performance differences get even more extreme (e.g.¬†if you only have one core, you have to multiply 37 with a number slightly smaller than 4).&lt;/p&gt;
&lt;p&gt;How do &lt;code&gt;vcovBS()&#39;s&lt;/code&gt; and &lt;code&gt;boottest()&#39;s&lt;/code&gt; results compare?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(boot_fast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## boottest.lm(object = lm_fit, clustid = c(&amp;quot;group_id1&amp;quot;), param = &amp;quot;treatment&amp;quot;, 
##     B = B, seed = 3, nthreads = 1)
##  
##  Hypothesis: 1*treatment = 0
##  Observations: 10000
##  Bootstr. Iter: 9999
##  Bootstr. Type: rademacher
##  Clustering: 1-way
##  Confidence Sets: 95%
##  Number of Clusters: 42
## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              term estimate statistic p.value conf.low conf.high
## 1 1*treatment = 0    0.002     0.516   0.605   -0.007     0.012&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmtest::coeftest(x = lm_fit, vcov = boot_slow)[2,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Estimate  Std. Error     t value    Pr(&amp;gt;|t|) 
## 0.002387792 0.004571759 0.522291836 0.601478745&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmtest::coefci(x = lm_fit, vcov = boot_slow)[2,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        2.5 %       97.5 % 
## -0.006573777  0.011349362&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Between the two implementations, the bootstrapped t-statistics, p-values and confidence intervals are almost identical. They are not exactly identical for two reasons: first due to sampling uncertainty in the bootstrap, and second because &lt;code&gt;vcovBS&lt;/code&gt; does not apply any small sample adjustments (at least I could not find anything related to small-sample adjustments in both documentation and source code).&lt;/p&gt;
&lt;p&gt;The speed gains of &lt;code&gt;fwildclusterboot&lt;/code&gt; scale well in the number of bootstrap iterations. For &lt;span class=&#34;math inline&#34;&gt;\(B = 99.999\)&lt;/span&gt; iterations, it finishes in around one second. For &lt;code&gt;vcovBS&lt;/code&gt;, you can expect a linear increase in run-time in the number of bootstrap iterations: a ten-fold increase in bootstrap iterations will increase run-time to around 360 seconds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 99999

bench2f &amp;lt;- 
bench::mark(
  boot_fast =
    fwildclusterboot::boottest(lm_fit,
                             clustid = c(&amp;quot;group_id1&amp;quot;),
                             B = B,
                             param = &amp;quot;treatment&amp;quot;,
                             seed = 3,
                             nthreads = 1), 
  iterations = 10
)

bench2f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast     476ms    571ms      1.72     727MB     11.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What happens if we increase the sample size to &lt;span class=&#34;math inline&#34;&gt;\(N = 100.000\)&lt;/span&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N &amp;lt;- 100000
data &amp;lt;- fwildclusterboot:::create_data(N = N,
                                         N_G1 = 50, icc1 = 0.1,
                                         N_G2 = 20, icc2 = 0.8,
                                         numb_fe1 = 10,
                                         numb_fe2 = 10,
                                         seed = seed,
                                         weights = 1:N)
lm_fit &amp;lt;- lm(proposition_vote ~ treatment + as.factor(Q1_immigration) + as.factor(Q2_defense), data)
B &amp;lt;- 9999
# wild cluster bootstrap via sandwich::vcovBS
bench3 &amp;lt;- bench::mark(
  boot_slow = sandwich::vcovBS(lm_fit,
                                R = B,
                                cluster = ~ group_id1,
                                cores = 4), 
  iterations = 1)
bench3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_slow     8.32m    8.32m   0.00200    31.2MB        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More than 8 minutes pass before &lt;code&gt;vcovBS()&lt;/code&gt; finishes. How does &lt;code&gt;boottest()&lt;/code&gt; do in comparison?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wild cluster bootstrap via fwildclusterboot::boottest()

bench3f &amp;lt;- 
bench::mark(
  boot_fast =
    fwildclusterboot::boottest(lm_fit,
                             clustid = c(&amp;quot;group_id1&amp;quot;),
                             B = B,
                             param = &amp;quot;treatment&amp;quot;,
                             seed = 3,
                             nthreads = 1), 
iterations = 5)
bench3f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast     310ms    333ms      2.68     308MB     10.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;B = 9999&lt;/code&gt; iterations, &lt;code&gt;boottest()&lt;/code&gt; runs for around 0.33 seconds, while &lt;code&gt;vcovBS()&lt;/code&gt; only finishes after 499.36 seconds. &lt;code&gt;fwildclusterboot::boottest()&lt;/code&gt; is 1499 times faster than &lt;code&gt;sandwich::vcovBS&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;As a conclusion: if you face a ‚Äúsmall number of clusters‚Äù problem and want to reduce your daily ‚òï consumption, you should consider using &lt;a href=&#34;https://github.com/s3alfisc/fwildclusterboot&#34;&gt;fwildclusterboot&lt;/a&gt;, Stata‚Äôs &lt;a href=&#34;https://github.com/droodman/boottest&#34;&gt;boottest&lt;/a&gt;, or &lt;a href=&#34;https://github.com/droodman/WildBootTests.jl&#34;&gt;WildBootTests.jl&lt;/a&gt;, which is a novel Julia implementation of the ‚Äúfast algorithm‚Äù. If all of this seems like black magic to you and you want to learn more about the ‚Äúfast algorithm‚Äù, I cannot recommend the ‚ÄúFast &amp;amp; Wild‚Äù paper highly enough.&lt;/p&gt;
&lt;div id=&#34;literature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Literature&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;‚ÄúFast &amp;amp; Wild‚Äù, Roodman et al.¬†(2019), The Stata Journal&lt;/li&gt;
&lt;li&gt;‚ÄúBootstrap-Based Improvements for Inference with Clustered Errors‚Äù, Cameron, Gelbach &amp;amp; Miller (2008), The Review of Economics and Statistics&lt;/li&gt;
&lt;li&gt;‚ÄúCluster-robust inference: A guide to empirical practice‚Äù (2020), MacKinnon, Oerregaard Nielsen &amp;amp; Webb, Working Paper&lt;/li&gt;
&lt;li&gt;‚ÄúMostly Harmless Econometrics‚Äù, Angrist &amp;amp; Pischke (2009), Princeton University Press&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>    </item>
    
  </channel>
</rss>
