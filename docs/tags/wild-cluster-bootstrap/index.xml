<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>    <link>https://s3alfisc.github.io/blog/tags/wild-cluster-bootstrap/</link>
    <description>Recent blog posts by </description>    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 18 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://s3alfisc.github.io/blog/tags/wild-cluster-bootstrap/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Even faster Wild Cluster Bootstrap Inference in R via WildBootTests.jl üöÄ</title>
      <link>https://s3alfisc.github.io/blog/post/2022-04-18-fwildclusterboot-0-8-on-cran/</link>
      <pubDate>Mon, 18 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://s3alfisc.github.io/blog/post/2022-04-18-fwildclusterboot-0-8-on-cran/</guid>
   <description>
&lt;script src=&#34;https://s3alfisc.github.io/blog/post/2022-04-18-fwildclusterboot-0-8-on-cran/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://s3alfisc.github.io/blog/post/2022-04-18-fwildclusterboot-0-8-on-cran/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;In the last few months, I have spent quite a bit of time working with a &lt;code&gt;Julia&lt;/code&gt; package - &lt;a href=&#34;https://github.com/droodman/WildBootTests.jl&#34;&gt;WildBootTests.jl&lt;/a&gt; - and towards integrating it into &lt;code&gt;fwildclusterboot&lt;/code&gt; via the awesome &lt;a href=&#34;https://github.com/stefan-m-lenz/JuliaConnectoR&#34;&gt;JuliaConnectoR&lt;/a&gt;.
Now &lt;code&gt;fwildclusterboot&lt;/code&gt; 0.8 has made its way to &lt;a href=&#34;https://cran.rstudio.com/web/packages/fwildclusterboot/index.html&#34;&gt;CRAN&lt;/a&gt;, so I thought it would be time to convince you to install Julia and to run your wild bootstraps through &lt;code&gt;WildBootTests.jl&lt;/code&gt; - but of course, still from R. üòÑ&lt;/p&gt;
&lt;div id=&#34;wildboottests.jl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;‚ÄòWildBootTests.jl‚Äô&lt;/h2&gt;
&lt;p&gt;A few months ago, I wrote a blog post on the outstanding speed gains that can be achieved by the ‚Äòfast‚Äô wild cluster bootstrap algorithm, which is implemented in R in the &lt;code&gt;fwildclusterboot&lt;/code&gt; package. In some benchmarks, &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; &lt;code&gt;boottest()&lt;/code&gt; function ran the wild cluster bootstrap &lt;a href=&#34;https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/&#34;&gt;more than 1000 times faster&lt;/a&gt; than &lt;code&gt;sandwich::vcovBS&lt;/code&gt;! Amazingly, it turns out that &lt;code&gt;WildBootTests.jl&lt;/code&gt; is &lt;strong&gt;even faster&lt;/strong&gt; than the algorithm in &lt;code&gt;fwildclusterboot&lt;/code&gt; or Stata‚Äôs &lt;code&gt;boottest&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;But we have all heard that &lt;code&gt;Julia&lt;/code&gt; is fast, so it‚Äôs maybe no too surprising that &lt;code&gt;WildBootTests.jl&lt;/code&gt; shines with speed. In my opinion, there are at least three other reason why it‚Äôs worth to try out &lt;code&gt;WildBootTests.jl&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; is very memory efficient&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; implements the wild cluster bootstrap for IV regression by &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1198/jbes.2009.07221&#34;&gt;Davidson &amp;amp; MacKinnon&lt;/a&gt;, and it‚Äôs blazing fast.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; allows for wild cluster bootstrapped F-tests &lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before I‚Äôll start showcasing &lt;code&gt;WildBootTests.jl&lt;/code&gt;, I will quickly describe how to access &lt;code&gt;WildBootTests.jl&lt;/code&gt; from R via &lt;code&gt;fwildclusterboot&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting Started&lt;/h3&gt;
&lt;p&gt;To run &lt;code&gt;WildBootTests.jl&lt;/code&gt; through &lt;code&gt;fwildclusterboot&lt;/code&gt;, both &lt;code&gt;Julia&lt;/code&gt; and &lt;code&gt;WildBootTests.jl&lt;/code&gt; need to be installed. The best place to install &lt;code&gt;Julia&lt;/code&gt; is its &lt;a href=&#34;https://julialang.org/&#34;&gt;homepage&lt;/a&gt; - just follow the instructions you find there. To facilitate getting started with everything else, I have written a small package, &lt;code&gt;JuliaConnectoR.utils&lt;/code&gt;, which aims to help to install &lt;code&gt;WildBootTests.jl&lt;/code&gt; and all its dependencies from within R and to connect &lt;code&gt;Julia&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; via the &lt;code&gt;JuliaConnectoR&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;So after installing &lt;code&gt;Julia&lt;/code&gt;, simply run &lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;s3alfisc/JuliaConnectoR.utils&amp;quot;)

library(JuliaConnectoR.utils)
# connect julia and R
connect_julia_r()
# install WildBootTests.jl
install_julia_packages(&amp;quot;WildBootTests.jl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you‚Äôre good to go and can wild cluster bootstrap via &lt;code&gt;WildBootTests.jl&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-first-bootstrap-via-wildboottests.jl&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A first bootstrap via &lt;code&gt;WildBootTests.jl&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The only required things left are a) a regression model to bootstrap and b) to specify &lt;code&gt;boottest()&#39;s&lt;/code&gt; &lt;code&gt;boot_algo&lt;/code&gt; function argument, so let‚Äôs start with simulating some data and fitting a regression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fwildclusterboot)
library(modelsummary)

N &amp;lt;- 100000

data &amp;lt;- fwildclusterboot:::create_data(
  N = N,
  N_G1 = 50, icc1 = 0.1,
  N_G2 = 20, icc2 = 0.8,
  numb_fe1 = 10,
  numb_fe2 = 10,
  seed = 123,
  weights = 1:N
)

lm_fit &amp;lt;- lm(
  proposition_vote ~ treatment + as.factor(Q1_immigration) + as.factor(Q2_defense), 
  data
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, &lt;code&gt;boottest()&lt;/code&gt; will run &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; R-implementation of the wild cluster bootstrap. To run through &lt;code&gt;WildBootTests.jl&lt;/code&gt;, you have to specify the &lt;code&gt;boot_algo&lt;/code&gt; function argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot_r &amp;lt;-
  fwildclusterboot::boottest(
    lm_fit,
    clustid = c(&amp;quot;group_id1&amp;quot;),
    B = 9999,
    param = &amp;quot;treatment&amp;quot;,
    seed = 3,
    nthreads = 1
)
    
boot_julia &amp;lt;-
  fwildclusterboot::boottest(
    lm_fit,
    clustid = c(&amp;quot;group_id1&amp;quot;),
    B = 9999,
    param = &amp;quot;treatment&amp;quot;,
    seed = 3,
    nthreads = 1, 
    boot_algo = &amp;quot;WildBootTests.jl&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the first call of &lt;code&gt;WildBootTests.jl&lt;/code&gt; takes around 10-20 seconds to, which is due to the fact that the Julia code being run is initially pre(-JIT)-compiled.&lt;/p&gt;
&lt;p&gt;Of course, it is good to see that the R implementation of the fast wild cluster bootstrap and &lt;code&gt;WildBootTests.jl&lt;/code&gt; lead to (almost) identical inferences:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;msummary(
  list(
    &amp;quot;R&amp;quot; = boot_r,
    &amp;quot;Julia&amp;quot; = boot_julia
  ), 
  estimate = &amp;quot;{estimate} ({p.value})&amp;quot;, 
  statistic = &amp;quot;[{conf.low}, {conf.high}]&amp;quot;  
)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
R
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
Julia
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1*treatment = 0
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.003 (0.002)
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.003 (0.001)
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;box-shadow: 0px 1px&#34;&gt;
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[0.001, 0.005]
&lt;/td&gt;
&lt;td style=&#34;text-align:center;box-shadow: 0px 1px&#34;&gt;
[0.001, 0.006]
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Num.Obs.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
100000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
100000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.159
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.159
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
R2 Adj.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.159
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.159
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AIC
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-46670.1
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-46670.1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
BIC
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-46470.4
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
-46470.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Log.Lik.
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
23356.067
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
23356.067
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now that I have shown how it works, let‚Äôs proceed to the next question: why should you install &lt;code&gt;Julia&lt;/code&gt; and run &lt;code&gt;WildBootTests.jl&lt;/code&gt; if the ‚Äòfast‚Äô algorithm is already implemented in ‚Äònative‚Äô R?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reason-i-it-is-extremely-fast&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reason I: It is extremely fast&lt;/h3&gt;
&lt;p&gt;In short: &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; R algo is fast, but we all know that &lt;code&gt;Julia&lt;/code&gt; is faster, and &lt;code&gt;WildBootTests.jl&lt;/code&gt; turns the speed of the wild cluster bootstrap from 10 to 11:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.giphy.com/media/lvlLuc2zhi39C/giphy.gif&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Turning the overdrive from 10 to 11 with WildBootTests.jl&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In a blog post from a few months ago, I claimed that &lt;a href=&#34;https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/&#34;&gt;&lt;code&gt;fwildclusterboot&lt;/code&gt; was 1000 times faster than &lt;code&gt;sandwich&#39;s&lt;/code&gt; &lt;code&gt;vcovBS()&lt;/code&gt; function&lt;/a&gt;. Below, I run the same problem, once for &lt;code&gt;boot_algo = &#34;R&#34;&lt;/code&gt; and once with &lt;code&gt;boot_algo = &#34;WildBootTests.jl&#34;&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 9999

bench &amp;lt;- bench::mark(
    boot_r =
    fwildclusterboot::boottest(
      lm_fit,
      clustid = c(&amp;quot;group_id1&amp;quot;),
      B = B,
      param = &amp;quot;treatment&amp;quot;,
      seed = 3,
      nthreads = 1
    ),
    boot_julia =
    fwildclusterboot::boottest(
      lm_fit,
      clustid = c(&amp;quot;group_id1&amp;quot;),
      B = B,
      param = &amp;quot;treatment&amp;quot;,
      seed = 3,
      nthreads = 1,
      boot_algo = &amp;quot;WildBootTests.jl&amp;quot;
    ),
  iterations = 3,
  check = FALSE
)

bench&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_r        737ms    758ms      1.32     304MB     6.60
## 2 boot_julia    266ms    342ms      2.85      97MB     4.75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a problem that took &lt;code&gt;boottest()&#39;s&lt;/code&gt; R algorithm around 1.5 seconds, &lt;code&gt;WildBootTests.jl&lt;/code&gt; finishes in around half a second. &lt;code&gt;WildBootTests.jl&lt;/code&gt; is around 3 times faster than &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; R implementation. Benchmarked against &lt;code&gt;sandwich::vcovBS&lt;/code&gt;, &lt;code&gt;WildBootTests.jl&lt;/code&gt; is around 4500x faster!&lt;/p&gt;
&lt;p&gt;In general, &lt;code&gt;WildBootTests.jl&lt;/code&gt; is - after compilation - at least an &lt;strong&gt;order of a magnitude&lt;/strong&gt; faster than &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; ‚ÄòR‚Äô algorithm. Below are benchmarks from a regression with &lt;span class=&#34;math inline&#34;&gt;\(N=10000\)&lt;/span&gt; observations and &lt;span class=&#34;math inline&#34;&gt;\(k=20\)&lt;/span&gt; covariates.&lt;/p&gt;
&lt;p&gt;While the R algorithm is competitive for ‚Äòsmall‚Äô problems, with a growing number of clusters and observations problems, &lt;code&gt;WildBootTests.jl&lt;/code&gt; clearly outperforms. For the most complex problem with &lt;span class=&#34;math inline&#34;&gt;\(G = 1000\)&lt;/span&gt; clusters and &lt;span class=&#34;math inline&#34;&gt;\(B =99999\)&lt;/span&gt; iterations, &lt;code&gt;WildBootTests.jl&lt;/code&gt; finishes in around 8 seconds, while the ‚ÄúR-algo‚Äù on 4 cores needs around twice as long. On one core, it runs for more than 40 seconds. And note that &lt;code&gt;WildBootTests.jl&lt;/code&gt; can also be run in parallel - check out &lt;code&gt;JuliaConnectoR.utils::set_julia_nthreads()&lt;/code&gt; for instructions on how to set the number of threads for &lt;code&gt;Julia&lt;/code&gt; from within R.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://s3alfisc.github.io/blog/post/2022-04-18-fwildclusterboot-0-8-on-cran/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;960&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wildboottests.jl-is-very-memory-efficient&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; is very memory-efficient&lt;/h3&gt;
&lt;p&gt;A second selling point of &lt;code&gt;WildBootTests.jl&lt;/code&gt; is that it is less memory-demanding. As &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; R algorithm is fully vectorized, a large bootstrap weights matrix &lt;span class=&#34;math inline&#34;&gt;\(v^{*}\)&lt;/span&gt; of dimensions &lt;span class=&#34;math inline&#34;&gt;\(G \times B\)&lt;/span&gt; is created and stored at once. As programming in Julia is much more encouraging towards writing loops, the large matrix does not need to be created at once, which prohibits the occasional out-of-memory error that the R algorithm encounters when &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; get too large.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wildboottests.jl-implements-the-wild-bootstrap-for-iv&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; implements the Wild Bootstrap for IV&lt;/h3&gt;
&lt;p&gt;Third (and maybe most importantly), &lt;code&gt;WildBootTests.jl&lt;/code&gt; offers additional functionality that has previously not been available to R users - most notably, it implements the WRE bootstrap for instrumental variable estimation from &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1198/jbes.2009.07221&#34;&gt;Davidson &amp;amp; MacKinnon&lt;/a&gt;. David Roodman, who is &lt;code&gt;WildBootTests.jl&#39;s&lt;/code&gt; author, has spend a lot of effort on &lt;a href=&#34;https://github.com/droodman/WildBootTests.jl/blob/master/in-case-i-get-hit-by-a-bus/Faster%20IV%203.docx&#34;&gt;optimizing the WRE‚Äôs performance&lt;/a&gt;, and as a result, it is blazing fast.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlsw88 &amp;lt;- haven::read_dta(&amp;quot;http://www.stata-press.com/data/r8/nlsw88.dta&amp;quot;)
head(nlsw88)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 17
##   idcode   age    race married never_married grade collgrad south    smsa c_city
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl+l&amp;gt; &amp;lt;dbl+l&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl+lb&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl+l&amp;gt;  &amp;lt;dbl&amp;gt;
## 1      1    37 2 [bla~ 0 [sin~             0    12 0 [not ~     0 1 [SMS~      0
## 2      2    37 2 [bla~ 0 [sin~             0    12 0 [not ~     0 1 [SMS~      1
## 3      3    42 2 [bla~ 0 [sin~             1    12 0 [not ~     0 1 [SMS~      1
## 4      4    43 1 [whi~ 1 [mar~             0    17 1 [coll~     0 1 [SMS~      0
## 5      6    42 1 [whi~ 1 [mar~             0    12 0 [not ~     0 1 [SMS~      0
## 6      7    39 1 [whi~ 1 [mar~             0    12 0 [not ~     0 1 [SMS~      0
## # ... with 7 more variables: industry &amp;lt;dbl+lbl&amp;gt;, occupation &amp;lt;dbl+lbl&amp;gt;,
## #   union &amp;lt;dbl+lbl&amp;gt;, wage &amp;lt;dbl&amp;gt;, hours &amp;lt;dbl&amp;gt;, ttl_exp &amp;lt;dbl&amp;gt;, tenure &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Currently, &lt;code&gt;fwildclusterboot&lt;/code&gt; allows to run the &lt;code&gt;WRE&lt;/code&gt; after IV-estimation via &lt;code&gt;ivreg::ivreg()&lt;/code&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ivreg)
# test that coefficient on tenure = 0, clustering errors by industry
iv_fit &amp;lt;- ivreg(wage ~ tenure + ttl_exp + collgrad | union + ttl_exp + collgrad, data = nlsw88)

boot_iv &amp;lt;-
boottest(
  iv_fit,
  param = &amp;quot;tenure&amp;quot;,
  B = 9999,
  clustid = &amp;quot;industry&amp;quot;
)

summary(iv_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## ivreg(formula = wage ~ tenure + ttl_exp + collgrad | union + 
##     ttl_exp + collgrad, data = nlsw88)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.3074  -2.8239  -0.3707   2.3584  37.8481 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)   4.9615     0.6206   7.994 2.27e-15 ***
## tenure        0.7409     0.1945   3.809 0.000144 ***
## ttl_exp      -0.2323     0.1413  -1.644 0.100439    
## collgrad      2.9808     0.2658  11.216  &amp;lt; 2e-16 ***
## 
## Diagnostic tests:
##                   df1  df2 statistic  p-value    
## Weak instruments    1 1864     29.61 5.97e-08 ***
## Wu-Hausman          1 1863     22.55 2.20e-06 ***
## Sargan              0   NA        NA       NA    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 4.803 on 1864 degrees of freedom
## Multiple R-Squared: -0.3255, Adjusted R-squared: -0.3277 
## Wald test: 117.6 on 3 and 1864 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(boot_iv)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## boottest.ivreg(object = iv_fit, clustid = &amp;quot;industry&amp;quot;, param = &amp;quot;tenure&amp;quot;, 
##     B = 9999)
##  
##  Hypothesis: 1*tenure = 0
##  Observations: 1855
##   Bootstr. Type: rademacher
##  Clustering: 1-way
##  Confidence Sets: 95%
##  Number of Clusters: 12
## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           term estimate statistic p.value conf.low conf.high
## 1 1*tenure = 0    0.741     2.491   0.022    0.202     1.798&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, &lt;code&gt;WildBootTests.jl&lt;/code&gt; supports wild cluster bootstrapping of multiple joint hypotheses. E.g. to jointly test the null that &lt;code&gt;tenure = 0&lt;/code&gt; and &lt;code&gt;collgrad = 0&lt;/code&gt; after a linear regression model, one would use &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; new &lt;code&gt;mboottest()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_fit &amp;lt;- lm(wage ~ tenure + ttl_exp + collgrad, data = nlsw88)

boot_q2 &amp;lt;-
mboottest(
  lm_fit,
  R = clubSandwich::constrain_zero(2:4, coef(lm_fit)),
  B = 9999,
  clustid = &amp;quot;industry&amp;quot;
)

summary(boot_q2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## mboottest.lm(object = lm_fit, clustid = &amp;quot;industry&amp;quot;, B = 9999, 
##     R = clubSandwich::constrain_zero(2:4, coef(lm_fit)))
##  
##  Hypothesis: Multivariate mboottest
##  Observations: 2217
##   Bootstr. Type: rademacher
##  Clustering: 1-way
##  Number of Clusters: 12
## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   teststat    p_val
## 1 56.79246 0.015625&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;WildBootTests.jl&lt;/code&gt; is outstanding software - do check it out!&lt;/p&gt;
&lt;p&gt;P.S. If you want all you wild bootstraps to run through &lt;code&gt;WildBootTests.jl&lt;/code&gt;, you can simply set a global variable at the top of your script:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setBoottest_boot_algo(&amp;quot;WildBootTests.jl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Afterwards, each call to &lt;code&gt;boottest()&lt;/code&gt; will simply default to &lt;code&gt;boot_algo = &#34;WildBootTests.jl&#34;&lt;/code&gt; unless explicitly stated otherwise.&lt;/p&gt;
&lt;!-- ## Wild Heteroskedastic Bootstrap --&gt;
&lt;!-- As a second new feature, version 0.8 of `fwildclusterboot` now ships an implementation of the &#39;heteroskedastic&#39; wild bootstrap. --&gt;
&lt;!-- In consequence, it is now possible to drop the `clustid` argument from `boottest()`, in which case a HC1-robust wild bootstrap is run: --&gt;
&lt;!-- ```{r} --&gt;
&lt;!-- boot_robust &lt;- boottest( --&gt;
&lt;!--   lm_fit, --&gt;
&lt;!--   param = &#34;tenure&#34;, --&gt;
&lt;!--   B = 9999 --&gt;
&lt;!-- ) --&gt;
&lt;!-- boot_cluster &lt;- boottest( --&gt;
&lt;!--   lm_fit, --&gt;
&lt;!--   clustid = &#34;group_id1&#34;, --&gt;
&lt;!--   param = &#34;tenure&#34;, --&gt;
&lt;!--   B = 9999 --&gt;
&lt;!-- ) --&gt;
&lt;!-- msummary( --&gt;
&lt;!--   list( --&gt;
&lt;!--     boot_robust, --&gt;
&lt;!--     boot_cluster --&gt;
&lt;!--   ), --&gt;
&lt;!--   estimate = &#34;{estimate} ({p.value})&#34;, --&gt;
&lt;!--   statistic = &#34;[{conf.low}, {conf.high}]&#34; --&gt;
&lt;!-- ) --&gt;
&lt;!-- ``` --&gt;
&lt;!-- At the moment, the wild &#39;robust&#39; bootstrap does not calculate confidence intervals - this remains future work. --&gt;
&lt;!-- I believe that having a moderatly fast implementation of the robust wild bootstrap is a nice feature - but also useful for a new project I am working on - a package that implements [Romano-Wolf adjusted p-values based using the wild bootstrap](https://github.com/s3alfisc/wildrwolf). --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;implemented in R via the &lt;a href=&#34;https://github.com/meghapsimatrix/wildmeta&#34;&gt;wildmeta package&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;of course you also have to install &lt;code&gt;fwildclusterboot&lt;/code&gt;, which you can install from CRAN, github, and r-universe.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I plan to add support for IV estimation via &lt;code&gt;fixest&lt;/code&gt; and &lt;code&gt;lfe&lt;/code&gt; in the next weeks / months.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>    </item>
    
    <item>
      <title>1000x faster Wild Cluster Bootstrap Inference in R with fwildclusterboot üöÄ</title>
      <link>https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/</guid>
   <description>
&lt;script src=&#34;https://s3alfisc.github.io/blog/post/1000x-faster-wild-cluster-bootstrap-inference-in-r-with-fwildclusterboot/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;When you suspect that the error terms in your regression model are correlated within clusters, and the number of clusters is small, trouble might be running at you. In such a situation, common cluster robust standard errors tend to be downward biased - they are too eager to reject the null hypothesis. Since &lt;a href=&#34;https://www.jstor.org/stable/40043157&#34;&gt;Cameron, Gelbach &amp;amp; Miller&lt;/a&gt; first suggested that the wild cluster bootstrap might be preferable to sandwich standard errors when the number of clusters is small, it has become common practice among empirical economists to check their cluster robust inferences against the wild cluster bootstrap.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:pressure&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;duerer_lion.jpg&#34; alt=&#34;Not a wild bootstrap, but a wild lion, by Albrecht Duerer&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Not a wild bootstrap, but a wild lion, by Albrecht Duerer
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;At some point, I found myself in a ‚Äúsmall number of clusters‚Äù situation. I was trying to estimate a treatment effect for a sample of a few thousand observations, which were grouped into around 20 clusters. So I started to search for R packages that implement the wild cluster bootstrap, and found two implementations on CRAN: &lt;code&gt;sandwich&lt;/code&gt; and &lt;code&gt;clusterSEs&lt;/code&gt;. I opted for the &lt;code&gt;sandwich&lt;/code&gt; package (because it‚Äôs actually a really great package) and fit my regression model via &lt;code&gt;lm()&lt;/code&gt;. Then I started to bootstrap with sandwich‚Äôs &lt;code&gt;vcovBS()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;So the bootstrap ran ‚Ä¶ and I waited. Eventually, I left my office to get some coffee with a colleague, returned to my desk ‚Ä¶ and the bootstrap still ran, and I waited even longer.&lt;/p&gt;
&lt;p&gt;But while the bootstrap was running, I scrolled the web and stumbled over the &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/1536867X19830877?journalCode=stja&#34;&gt;‚ÄúFast &amp;amp; Wild‚Äù paper&lt;/a&gt; by Roodman et al (2019). The claimed performance in the paper seemed to good to be true: bootstrap inference with several thousands of iterations, in a fraction of a second? The paper presents a Stata implementation of the fast algorithm, &lt;a href=&#34;https://github.com/droodman/bottest&#34;&gt;boottest&lt;/a&gt;, and that was a good enough reason for me to start up a Stata session to try it out.&lt;/p&gt;
&lt;p&gt;And indeed, &lt;code&gt;boottest&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; mind-blowingly fast: the bootstrap finished almost instantaneously. I was hooked: how was it possible that &lt;code&gt;boottest&lt;/code&gt; was &lt;em&gt;so damn fast&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Luckily, the ‚ÄúFast &amp;amp; Wild‚Äù paper explains the algorithm powering &lt;code&gt;boottest&lt;/code&gt; in great detail. Out of curiosity, I started to implement it in R, and the &lt;code&gt;fwildclusterboot&lt;/code&gt; package is the result of this effort. Now, was it worth all the work? How much faster is the ‚Äúfast algorithm‚Äù implemented in &lt;code&gt;fwildclusterboot&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;To compare &lt;code&gt;fwildclusterboot&#39;s&lt;/code&gt; performance to &lt;code&gt;sandwich&lt;/code&gt;, I simulate a data set with &lt;span class=&#34;math inline&#34;&gt;\(N = 10.000\)&lt;/span&gt; observations and &lt;span class=&#34;math inline&#34;&gt;\(N_G = 42\)&lt;/span&gt; distinct clusters (42 is the magic number of clusters for which the economics profession has decided that large N asymptotics fail, see Angrist &amp;amp; Pischke‚Äôs ‚ÄúMostly Harmless‚Äù, Chapter 8.2.3) and fit a regression model via &lt;code&gt;lm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fwildclusterboot)
library(sandwich)
library(lmtest)
library(bench)

# simulate data
seed &amp;lt;- 236723478
N &amp;lt;- 10000
data &amp;lt;- fwildclusterboot:::create_data(N = N,
                                         N_G1 = 42, icc1 = 0.1,
                                         N_G2 = 20, icc2 = 0.8,
                                         numb_fe1 = 10,
                                         numb_fe2 = 10,
                                         seed = seed,
                                         weights = 1:N)
lm_fit &amp;lt;- lm(proposition_vote ~ treatment + as.factor(Q1_immigration) + as.factor(Q2_defense), data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the first experiment, the bootstrap will run for &lt;span class=&#34;math inline&#34;&gt;\(B = 9999\)&lt;/span&gt; iterations. For the estimation via &lt;code&gt;vcovBS&lt;/code&gt;, we will use 4 cores.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 9999
# wild cluster bootstrap via sandwich::vcovBS

bench1 &amp;lt;- 
bench::mark(
  boot_slow = sandwich::vcovBS(lm_fit,
                                R = B,
                                cluster = ~ group_id1,
                                cores = 4), 
  iterations = 1
)
bench1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_slow     36.9s    36.9s    0.0271    12.7MB        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;vcovBS()&lt;/code&gt; finishes in around 37 seconds - that‚Äôs not too bad, isn‚Äôt it?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wild cluster bootstrap via fwildclusterboot::boottest()
bench1f &amp;lt;- 
bench::mark(boot_fast =
                   fwildclusterboot::boottest(lm_fit,
                                              clustid = c(&amp;quot;group_id1&amp;quot;),
                                              B = B,
                                              param = &amp;quot;treatment&amp;quot;,
                                              seed = 3,
                                              nthreads = 1), 
            iterations = 25)
bench1f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast    73.3ms   81.7ms      9.48    98.7MB     26.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While &lt;code&gt;sandwich::vcovBS()&lt;/code&gt; takes almost 36.9 seconds, &lt;code&gt;fwildclusterboot::boottest()&lt;/code&gt; runs in around one fifth of a second üöÄ. Yes, really: one fifth of a second! That‚Äôs a speed gain of a factor of 451! If you don‚Äôt have 4 cores available, performance differences get even more extreme (e.g.¬†if you only have one core, you have to multiply 37 with a number slightly smaller than 4).&lt;/p&gt;
&lt;p&gt;How do &lt;code&gt;vcovBS()&#39;s&lt;/code&gt; and &lt;code&gt;boottest()&#39;s&lt;/code&gt; results compare?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(boot_fast)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## boottest.lm(object = lm_fit, clustid = c(&amp;quot;group_id1&amp;quot;), param = &amp;quot;treatment&amp;quot;, 
##     B = B, seed = 3, nthreads = 1)
##  
##  Hypothesis: 1*treatment = 0
##  Observations: 10000
##  Bootstr. Iter: 9999
##  Bootstr. Type: rademacher
##  Clustering: 1-way
##  Confidence Sets: 95%
##  Number of Clusters: 42
## &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              term estimate statistic p.value conf.low conf.high
## 1 1*treatment = 0    0.002     0.516   0.605   -0.007     0.012&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmtest::coeftest(x = lm_fit, vcov = boot_slow)[2,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Estimate  Std. Error     t value    Pr(&amp;gt;|t|) 
## 0.002387792 0.004571759 0.522291836 0.601478745&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lmtest::coefci(x = lm_fit, vcov = boot_slow)[2,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        2.5 %       97.5 % 
## -0.006573777  0.011349362&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Between the two implementations, the bootstrapped t-statistics, p-values and confidence intervals are almost identical. They are not exactly identical for two reasons: first due to sampling uncertainty in the bootstrap, and second because &lt;code&gt;vcovBS&lt;/code&gt; does not apply any small sample adjustments (at least I could not find anything related to small-sample adjustments in both documentation and source code).&lt;/p&gt;
&lt;p&gt;The speed gains of &lt;code&gt;fwildclusterboot&lt;/code&gt; scale well in the number of bootstrap iterations. For &lt;span class=&#34;math inline&#34;&gt;\(B = 99.999\)&lt;/span&gt; iterations, it finishes in around one second. For &lt;code&gt;vcovBS&lt;/code&gt;, you can expect a linear increase in run-time in the number of bootstrap iterations: a ten-fold increase in bootstrap iterations will increase run-time to around 360 seconds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 99999

bench2f &amp;lt;- 
bench::mark(
  boot_fast =
    fwildclusterboot::boottest(lm_fit,
                             clustid = c(&amp;quot;group_id1&amp;quot;),
                             B = B,
                             param = &amp;quot;treatment&amp;quot;,
                             seed = 3,
                             nthreads = 1), 
  iterations = 10
)

bench2f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast     476ms    571ms      1.72     727MB     11.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What happens if we increase the sample size to &lt;span class=&#34;math inline&#34;&gt;\(N = 100.000\)&lt;/span&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N &amp;lt;- 100000
data &amp;lt;- fwildclusterboot:::create_data(N = N,
                                         N_G1 = 50, icc1 = 0.1,
                                         N_G2 = 20, icc2 = 0.8,
                                         numb_fe1 = 10,
                                         numb_fe2 = 10,
                                         seed = seed,
                                         weights = 1:N)
lm_fit &amp;lt;- lm(proposition_vote ~ treatment + as.factor(Q1_immigration) + as.factor(Q2_defense), data)
B &amp;lt;- 9999
# wild cluster bootstrap via sandwich::vcovBS
bench3 &amp;lt;- bench::mark(
  boot_slow = sandwich::vcovBS(lm_fit,
                                R = B,
                                cluster = ~ group_id1,
                                cores = 4), 
  iterations = 1)
bench3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_slow     8.32m    8.32m   0.00200    31.2MB        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More than 8 minutes pass before &lt;code&gt;vcovBS()&lt;/code&gt; finishes. How does &lt;code&gt;boottest()&lt;/code&gt; do in comparison?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# wild cluster bootstrap via fwildclusterboot::boottest()

bench3f &amp;lt;- 
bench::mark(
  boot_fast =
    fwildclusterboot::boottest(lm_fit,
                             clustid = c(&amp;quot;group_id1&amp;quot;),
                             B = B,
                             param = &amp;quot;treatment&amp;quot;,
                             seed = 3,
                             nthreads = 1), 
iterations = 5)
bench3f&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 6
##   expression      min   median `itr/sec` mem_alloc `gc/sec`
##   &amp;lt;bch:expr&amp;gt; &amp;lt;bch:tm&amp;gt; &amp;lt;bch:tm&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;bch:byt&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 boot_fast     310ms    333ms      2.68     308MB     10.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;B = 9999&lt;/code&gt; iterations, &lt;code&gt;boottest()&lt;/code&gt; runs for around 0.33 seconds, while &lt;code&gt;vcovBS()&lt;/code&gt; only finishes after 499.36 seconds. &lt;code&gt;fwildclusterboot::boottest()&lt;/code&gt; is 1499 times faster than &lt;code&gt;sandwich::vcovBS&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;As a conclusion: if you face a ‚Äúsmall number of clusters‚Äù problem and want to reduce your daily ‚òï consumption, you should consider using &lt;a href=&#34;https://github.com/s3alfisc/fwildclusterboot&#34;&gt;fwildclusterboot&lt;/a&gt;, Stata‚Äôs &lt;a href=&#34;https://github.com/droodman/boottest&#34;&gt;boottest&lt;/a&gt;, or &lt;a href=&#34;https://github.com/droodman/WildBootTests.jl&#34;&gt;WildBootTests.jl&lt;/a&gt;, which is a novel Julia implementation of the ‚Äúfast algorithm‚Äù. If all of this seems like black magic to you and you want to learn more about the ‚Äúfast algorithm‚Äù, I cannot recommend the ‚ÄúFast &amp;amp; Wild‚Äù paper highly enough.&lt;/p&gt;
&lt;div id=&#34;literature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Literature&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;‚ÄúFast &amp;amp; Wild‚Äù, Roodman et al.¬†(2019), The Stata Journal&lt;/li&gt;
&lt;li&gt;‚ÄúBootstrap-Based Improvements for Inference with Clustered Errors‚Äù, Cameron, Gelbach &amp;amp; Miller (2008), The Review of Economics and Statistics&lt;/li&gt;
&lt;li&gt;‚ÄúCluster-robust inference: A guide to empirical practice‚Äù (2020), MacKinnon, Oerregaard Nielsen &amp;amp; Webb, Working Paper&lt;/li&gt;
&lt;li&gt;‚ÄúMostly Harmless Econometrics‚Äù, Angrist &amp;amp; Pischke (2009), Princeton University Press&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>    </item>
    
  </channel>
</rss>
